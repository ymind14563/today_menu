name: Daily Menu Crawler

on:
  schedule:
    # UTC 21:00~23:00 = KST 06:00~08:00 (60분 간격, 월 ~ 금)
    - cron: '0 21-23 * * 0-4'
  
    # UTC 00:00~00:59 = KST 09:00~09:59 (30분 간격, 월 ~ 금)
    - cron: '0,30 0 * * 1-5'
  
    # UTC 01:00~01:59 = KST 10:00~10:59 (15분 간격, 월 ~ 금)
    - cron: '0,15,30,45 1 * * 1-5'
  
    # UTC 02:00~02:59 = KST 11:00~11:59 (5분 간격, 월 ~ 금)
    - cron: '*/5 2 * * 1-5'


  workflow_dispatch:

jobs:
  crawl-and-deploy:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Seoul

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.TODAY_MENU_TOKEN }}

      - name: 크롤링 필요 여부 확인
        id: check
        run: |
          echo "last_urls.json 조회 중..."
          TODAY=$(date '+%Y-%m-%d')
          echo "오늘 날짜: $TODAY"

          if [ ! -f docs/last_urls.json ]; then
            echo "last_urls.json 파일이 없음. 크롤링 수행 필요."
            echo "run-crawler=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          N_Date=$(jq -r '.naver.saved_date // ""' docs/last_urls.json)
          K_Date=$(jq -r '.kakao.saved_date // ""' docs/last_urls.json)
          K_2_Date=$(jq -r '.kakao_2.saved_date // ""' docs/last_urls.json)

          echo "N_Date=$N_Date"
          echo "K_Date=$K_Date"
          echo "K_2_Date=$K_2_Date"

          if [[ "$N_Date" == "$TODAY"* && "$K_Date" == "$TODAY"* && "$K_2_Date" == "$TODAY"* ]]; then
            echo "세 메뉴 모두 오늘자로 저장되어 있습니다. 크롤링 생략."
            echo "run-crawler=false" >> $GITHUB_OUTPUT
          else
            echo "하나 이상 오늘자 아님 → 크롤링 필요"
            echo "run-crawler=true" >> $GITHUB_OUTPUT
          fi

      - name: Python 세팅
        if: steps.check.outputs.run-crawler == 'true'
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: dependencies 설치 (requirements.txt)
        if: steps.check.outputs.run-crawler == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: 크롤링 시작
        if: steps.check.outputs.run-crawler == 'true'
        run: |
          python menu_crawler/main.py

      - name: git push, html 업데이트
        if: steps.check.outputs.run-crawler == 'true'
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

          git add docs/

          # 기존 grep은 삭제된 줄 포함 + 부분 문자열 탐지였기 때문에 오탐 => 정규식으로 보완
          # ^ : 라인 시작,  \+ : git diff에서 추가된 줄만 탐지 (라인 앞에 '+' 붙음), .*"url": / .*"saved_date": : 해당 키가 포함된 라인인지 확인
          # 반드시 "추가된 줄" 중에 "url" 또는 "saved_date"가 들어간 경우만 감지해야함
          if git diff --cached docs/last_urls.json | grep -qE '^\+.*"url":|^\+.*"saved_date":'; then
            echo "주요 사항 변경"
            git config --global user.name "ymind14563"
            git config --global user.email "ymind14563@gmail.com"
            git commit -m "update: $(date '+%Y-%m-%d %H:%M')"
          else
            echo "last_checked 변경"
            git commit -m "chore: last_checked ($(date '+%Y-%m-%d %H:%M'))"
          fi

          git push
  
        
